# OpenNI: video and audio
[OpenNI][1]
[OpenNI api][2]
[csdn blog OpenNI][3]
[csdn blog][4]
[cnblog calibration][5]
[cvvision][6]
[csdn blog: opencv zhangzhenyou calib](http://blog.csdn.net/dcrmg/article/details/52929669)

## 0. There're 4 main classes:
>- openni::OpenNI: access of API
>- openni::Device
>- openni::VideoStream
>- openni::VideoFramRef: get one video stream frame from video stream data

## 1. Dataflow
>- (1). initialize openni environment  
>- (2). new openni::Device  
>- (3). open device  
>- (4). new openni::VideoStream  
>- (5). appoint VideoStream to get what type of data(infra/rgb/depth)  
>- (6). get data stream and process   
>- (7). destroy data stream  
>- (8). close device   
>- (9). shutdown openni environment  

## 2. Device()
when there're several sensors connected to pc:
1. get devices list by **openni::numerateDevices()**. 
2. get URI(Uniform Resource Identifier) by **openni::DeviceInfo::getUri()**, the output of this method is the input of **openni::Device::open()**
3. **Device::close()**: all the opened devices must be closed
4. **Device::isValid()**
5. **Device::hasSensor()**: sensor type 
>>- (1). SENSOR_IR
>>- (2). SENSOR_COLOR
>>- (3). SENSOR_DEPTH

## 3. VideoStream()
embedded all the data stream created by Device() class.
**VideoStream::create() -> VideoStream::start() -> VideoStream::stop()**


---

# Camera calibration
>- addChessboardPoints(): read series chess board images and detect corner points
>- calibrate(): get camera intrinsic/extrinsic matrix
>- remap(): implement initUndistortRectifyMap
>- addPoints(): be called after addChessboardPoints(), or manually call this method to add cornor points

Zhang Zhenyou
[blog about camera calibration](http://blog.csdn.net/dcrmg/article/details/52939318)
Why: in order to get intrinsic matrix of camera and extrinsic matrix -> to rectify the images got -> to get undistored(little distored) images
input: all the iner corner image coordinates and spatial coordinates
output: intrinsic and extrinsic matrix 

1. calibration board
2. extract corner information of each calib image
3. corner subpix
4. draw iner corner(optional, just for display)
5. calibration
6. evaluate
7. check, unrectify image

[Camera pose estimation](http://blog.csdn.net/aptx704610875/article/details/48915149)

Image Coordinate, Camera Coordinate, World Coordinate


---

[opencv python](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_calib3d/py_calibration/py_calibration.html)
[calibration math](http://blog.csdn.net/aptx704610875/article/details/48914043)
1. chessboard images: at least 3 (different position, different orientation, different angles), 10~20
2. extract corner information of each chessboard image:  
cv::findChessboardCorners(8bit grey image / rgb image, chessboard iner corner rows and cols, &corner image coordinates, flag for calibration)
**3**. extract cornersubpix information of each chessboard image:  
cv::cornerSubPix(better 8bit grey image, first corner image coordinates, window size, zero zone, criteria)
(another approach is: cv::find4QuadCornerSubpix) ?: what's the differences?
4. draw iner corner:  
cv::drawChessboardCorners(8bit grey image / rgb image, chessboard rows and corners, corner image coordinates, flag for whether all the corner points are detected)
5. calibration:   
cv::calibrateCamera(spatial coordinates, image coordinates, image pixel size, camera intrinsic matrix, distortion matrix, rotation vector, translation vector, flags for calibration approach)
6. evaluate:  
re-projection error
cv::projectPoints  
7. check, rectify distord image:  
(1). approach 1: cv::initUndistortRectifyMap and cv::remap
(2). approach 2: cv::undistort


requires white space(like a square-thick border, the wider the better) around the board to make the detection more robust in various environments. Otherwise, if there is no border and the background is dark, the outer black squares cannot be segmented properly and so the square grouping and ordering algorithm fails

the opencv ```imread(), videoCapture()``` state that by default for 3-channel color images the data is stored in **BGR** order.  
Because BGR color format was popular among camera manufacturers and software providers. BGR was a choice made for historical reasons.
---

if an image size is 640*480, depth is 16 bits, than it has ? M data:
> 640\*480\*16 bit = 4915200 bit = 614400 bytes = 600 kb = 0.58 M

---
10-16 Mon
1. Obec code
5. pc: network driver

2.U: readme & welcome, finding lane lines video
3.parellel pse & interview
4.C: Lin, week1 video
[5]. 1000!

http://blog.csdn.net/app_12062011/article/details/52738147

10-17 Tue
1. calib
2. new sensor construct  -> readmd, image (check with Yehang)
3. network driver reinstall, update git version

4. search new sensor algo related paper
5. LiFeifei lecture 1

10-18 Wen
1. calib principle
2. new sensor construct  -> readmd, image

10-19 Thu
google c++ code style

10-20 Fri
[Obec Astra S version](https://orbbec3d.com/product-astra/)
[download](https://3dclub.orbbec3d.com/t/universal-download-thread-for-astra-series-cameras/622)
- Range: 0.4- to 2-meter 
- Depth Image Size: 640*480(VGA) @ 30FPS
- RGB Image Size: 640*480 @ 30FPS
- Field of View: 60 deg horiz x 49.5 deg vert (73 deg diagonal)
- Data Interface: USB 2.0
- Power: USB 2.0
---

---  

[1]http://openni.ru/openni-programmers-guide/index.html  
[2]http://www.openni.ru/wp-content/doxygen/html/index.html  
[3]http://blog.csdn.net/app_12062011/article/details/52738147  
[4]http://blog.csdn.net/App_12062011  
[5]http://www.cnblogs.com/haoxing990/p/4589461.html  
[6]http://www.cvvision.cn/cv.html   

---

De-mystifying Good Research and Good Papers
By Fei-Fei Li, 2009.03.01

Please remember this:
1000+ computer vision papers get published every year!
Only 5-10 are worth reading and remembering!

Since many of you are writing your papers now, I thought that I'd share these thoughts with you. I probably have said all these at various points during our group and individual meetings. But as I continue my AC reviews these days (that's 70 papers and 200+ reviews -- between me and my AC partner), these following points just keep coming up. Not enough people conduct first class research. And not enough people write good papers.

- Every research project and every paper should be conducted and written with one singular purpose: **to genuinely advance the field of computer vision**. So when you conceptualize and carry out your work, you need to be constantly asking yourself this question in the most critical way you could – “Would my work define or reshape xxx (problem, field, technique) in the future?” This means publishing papers is NOT about "this has not been published or written before, let me do it", nor is it about “let me find an arcane little problem that can get me an easy poster”. It's about "if I do this, I could offer a better solution to this important problem," or “if I do this, I could add a genuinely new and important piece of knowledge to the field.” You should always conduct research with the goal that it could be directly used by many people (or industry). In other words, your research topic should have many ‘customers’, and your solution would be the one they want to use.

- A good research project is not about the past (i.e. obtaining a higher performance than the previous N papers). It's about the future (i.e. inspiring N future papers to follow and cite you, N->inf).

- A CVPR'09 submission with a Caltech101 performance of 95% received 444 (3 weakly rejects) this year, and will be rejected. This is by far the highest performance I've seen for Caltech101. So why is this paper rejected? Because it doesn't teach us anything, and no one will likely be using it for anything. It uses a known technique (at least for many people already) with super tweaked parameters custom-made for the dataset that is no longer a good reflection of real-world image data. It uses a BoW representation without object level understanding. All reviewers (from very different angles) asked the same question "what do we learn from your method?" And the only sensible answer I could come up with is that Caltech101 is no longer a good dataset.

- Einstein used to say: everything should be made as simple as possible, but not simpler. Your method/algorithm should be the most simple, coherent and principled one you could think of for solving this problem. Computer vision research, like many other areas of engineering and science research, is about problems, not equations. No one appreciates a complicated graphical model with super fancy inference techniques that essentially achieves the same result as a simple SVM -- unless it offers deeper understanding of your data that no other simpler methods could offer. A method in which you have to manually tune many parameters is not considered principled or coherent.

- This might sound corny, but it is true. You're PhD students in one of the best universities in the world. This means you embody the highest level of intellectualism of humanity today. This means you are NOT a technician and you are NOT a coding monkey. When you write your paper, you communicate and . That's what a paper is about. This is how you should approach your writing. You need to feel proud of your paper not just for the day or week it is finished, but many for many years to come.

- Set a high goal for yourself – the truth is, you can achieve it as long as you put your heart in it! When you think of your paper, ask yourself this question: Is this going to be among the 10 papers of 2009 that people will remember in computer vision? If not, why not? The truth is only 10+/-epsilon gets remembered every year. Most of the papers are just meaningless publication games. A long string of mediocre papers on your resume can at best get you a Google software engineer job (if at all – 2009.03 update: no, Google doesn’t hire PhD for this anymore). A couple of seminal papers can get you a faculty job in a top university. This is the truth that most graduate students don't know, or don't have a chance to know.

- Review process is highly random. But there is one golden rule that withstands the test of time and randomness -- badly written papers get bad reviews. Period. It doesn't matter if the idea is good, result is good, citations are good. Not at all. Writing is critical -- and this is ironic because engineers are the worst trained writers among all disciplines in a university. You need to discipline yourself: leave time for writing, think deeply about writing, and write it over and over again till it's as polished as you can think of.

- Last but not the least, please remember this rule: important problem (inspiring idea) + solid and novel theory + convincing and analytical experiments + good writing = seminal research + excellent paper. If any of these ingredients is weak, your paper, hence reviewer scores, would suffer.
