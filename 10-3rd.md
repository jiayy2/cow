# OpenNI: video and audio
[OpenNI][1]
[OpenNI api][2]
[csdn blog OpenNI][3]
[csdn blog][4]
[cnblog calibration][5]
[cvvision][6]

## 0. There're 4 main classes:
>- openni::OpenNI: access of API
>- openni::Device
>- openni::VideoStream
>- openni::VideoFramRef: get one video stream frame from video stream data

## 1. Dataflow
>- (1). initialize openni environment  
>- (2). new openni::Device  
>- (3). open device  
>- (4). new openni::VideoStream  
>- (5). appoint VideoStream to get what type of data(infra/rgb/depth)  
>- (6). get data stream and process   
>- (7). destroy data stream  
>- (8). close device   
>- (9). shutdown openni environment  

## 2. Device()
when there're several sensors connected to pc:
1. get devices list by **openni::numerateDevices()**. 
2. get URI(Uniform Resource Identifier) by **openni::DeviceInfo::getUri()**, the output of this method is the input of **openni::Device::open()**
3. **Device::close()**: all the opened devices must be closed
4. **Device::isValid()**
5. **Device::hasSensor()**: sensor type 
>>- (1). SENSOR_IR
>>- (2). SENSOR_COLOR
>>- (3). SENSOR_DEPTH

## 3. VideoStream()
embedded all the data stream created by Device() class.
**VideoStream::create() -> VideoStream::start() -> VideoStream::stop()**


---

# Camera calibration
>- addChessboardPoints(): read series chess board images and detect corner points
>- calibrate(): get camera intrinsic/extrinsic matrix
>- remap(): implement initUndistortRectifyMap
>- addPoints(): be called after addChessboardPoints(), or manually call this method to add cornor points


---

if an image size is 640*480, depth is 16 bits, than it has ? M data:
> 640\*480\*16 bit = 4915200 bit = 614400 bytes = 600 kb = 0.58 M


---  

[1]http://openni.ru/openni-programmers-guide/index.html  
[2]http://www.openni.ru/wp-content/doxygen/html/index.html  
[3]http://blog.csdn.net/app_12062011/article/details/52738147  
[4]http://blog.csdn.net/App_12062011  
[5]http://www.cnblogs.com/haoxing990/p/4589461.html  
[6]http://www.cvvision.cn/cv.html   

